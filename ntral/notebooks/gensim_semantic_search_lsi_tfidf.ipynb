{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim text retrieval semantic engine\n",
    "\n",
    "* Gensim text retrieval semantic engine with Latent Semantic Indexing (LSA in TR).\n",
    "* Dataset is https://www.kaggle.com/rmisra/news-category-dataset with 202372 entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/News_Category_Dataset_v2.json\"\n",
    "DATA_LEN = 202372"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "def tokenize(text):\n",
    "    return [token for token in gensim.utils.simple_preprocess(text) if token not in STOPWORDS]\n",
    "\n",
    "def iter_news(file):\n",
    "    for line in open(file):\n",
    "        line = json.loads(line)['headline'] + json.loads(line)['short_description']\n",
    "        tokens = tokenize(line)\n",
    "        yield line, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.7 s\n",
      "Dictionary(168877 unique tokens: ['america', 'children', 'day', 'husband', 'killed']...)\n"
     ]
    }
   ],
   "source": [
    "# stream just tokens\n",
    "doc_stream = (tokens for _, tokens in iter_news(DATA_PATH))\n",
    "\n",
    "# build dict\n",
    "%time id2word_news = gensim.corpora.Dictionary(doc_stream)\n",
    "print(id2word_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(14366 unique tokens: ['america', 'children', 'day', 'husband', 'killed']...)\n"
     ]
    }
   ],
   "source": [
    "# ignore words that appear in less than 20 documents or more than 10% documents\n",
    "id2word_news.filter_extremes(no_below=20, no_above=0.1)\n",
    "print(id2word_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsCorpus():\n",
    "    \n",
    "    def __init__(self, file, dictionary):\n",
    "        self.file = file\n",
    "        self.dict = dictionary\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.titles = []\n",
    "        for title, tokens in iter_news(self.file):\n",
    "            self.titles.append(title)\n",
    "            yield self.dict.doc2bow(tokens)\n",
    "        \n",
    "            \n",
    "# create a stream of bag-of-words vectors\n",
    "news_corpus = NewsCorpus(DATA_PATH, id2word_news)\n",
    "vector = next(iter(news_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.8 s\n"
     ]
    }
   ],
   "source": [
    "# store corpus\n",
    "%time gensim.corpora.MmCorpus.serialize('../data/news_bow.mm', news_corpus)\n",
    "\n",
    "# store dictionary\n",
    "id2word_news.save('../data/news.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MmCorpus(200853 documents, 14366 features, 2548042 non-zero entries)\n"
     ]
    }
   ],
   "source": [
    "# load dictionary\n",
    "id2word_news = gensim.corpora.Dictionary.load('../data/news.dict')\n",
    "\n",
    "# load corpus\n",
    "mm_corpus = gensim.corpora.MmCorpus('../data/news_bow.mm')\n",
    "print(mm_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.12 s\n"
     ]
    }
   ],
   "source": [
    "%time tfidf = gensim.models.TfidfModel(mm_corpus, id2word=id2word_news)\n",
    "tfidf.save('../data/tfidf_news.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 51.5 s\n"
     ]
    }
   ],
   "source": [
    "%time lsi = gensim.models.lsimodel.LsiModel(corpus=tfidf[mm_corpus], id2word=id2word_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi.save('../data/lsi_news.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = lsi.load('../data/lsi_news.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 51.9 s\n"
     ]
    }
   ],
   "source": [
    "# build the index\n",
    "from gensim import similarities\n",
    "%time index = similarities.MatrixSimilarity(lsi[mm_corpus])\n",
    "index.save('../data/lsi_news.index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "lsi = gensim.models.lsimodel.LsiModel.load('../data/lsi_news.model')\n",
    "tfidf = gensim.models.TfidfModel.load('../data/tfidf_news.model')\n",
    "index = gensim.similarities.MatrixSimilarity.load('../data/lsi_news.index')\n",
    "dictionary = gensim.corpora.Dictionary.load('../data/news.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform doc into lsi vector space (we need the model for this)\n",
    "doc = \"illness\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[tfidf[vec_bow]]\n",
    "\n",
    "# query doc (we need the index for this)\n",
    "sims = index[vec_lsi]\n",
    "\n",
    "# sort by similarity\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(104044, 0.8559768), (120903, 0.80635357), (199133, 0.80370283), (100521, 0.79226947), (92275, 0.7846557), (96541, 0.75075185), (74773, 0.73616123), (133521, 0.69531834), (125753, 0.69314253), (89698, 0.6643342)]\n"
     ]
    }
   ],
   "source": [
    "# print most similar docs\n",
    "print(sims[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 0.8559768199920654 | 104044 | Staring Into the Abyss of the Criminalization of Persons With Mental Illness |  |\n",
      "| 0.8063535690307617 | 120903 | Suspected Seattle Gunman Suffers From Severe Mental Illness: Lawyers |  |\n",
      "| 0.8037028312683105 | 199133 | Does Depression Exist? | If you call your sadness, irritability, loneliness, disappointments, and overwhelm \"the mental disorder of depression,\" does calling all that pain make it \"the mental disorder of depression\"? |\n",
      "| 0.7922694683074951 | 100521 | 'There's No Shame' In Talking About Mental Illness |  |\n",
      "| 0.7846556901931763 | 92275 | Mental Illness and Identity: Would I Shed My Bipolar Disorder Skin? |  |\n",
      "| 0.7507518529891968 | 96541 | My Mental Collection |  |\n",
      "| 0.7361612319946289 | 74773 | The Psychological Toll Of Racism In The Wake Of Mizzou | How writing about racism everyday interacts with my mental illness. |\n",
      "| 0.695318341255188 | 133521 | How to Get Rid of Secrets? Tell Them | by guest blogger Cristina Negr√≥n It took my own mental illness to fully embrace the fact that mental illness is just that |\n",
      "| 0.6931425333023071 | 125753 | Finding Hope and Help in Tragedy | Whenever a person with a mental disorder (or assumed to have a mental disorder), veteran or civilian, commits a violent act that makes headlines, there is a call to address the \"mental health issue\" in violent crimes. However, what is meant by the \"mental health issue\" is generally unclear. The fact is that killings and overall violence are extremely rare by people with serious mental illness. |\n",
      "| 0.6643341779708862 | 89698 | Being Vocal for Mental Health | What does it mean to be \"aware\" of mental health though? Of what should we be aware? |\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "sim_rank = sims[:10]\n",
    "sim_ids = [i[0] for i in sim_rank]\n",
    "\n",
    "fp = open(DATA_PATH)\n",
    "result = []\n",
    "for line_idx, line in enumerate(fp):\n",
    "    if line_idx in sim_ids:\n",
    "        sim_idx = sim_ids.index(line_idx)\n",
    "        sim_val = sim_rank[sim_idx]\n",
    "        line = json.loads(line)\n",
    "        result.append(\n",
    "            (sim_val, line['headline'], line['short_description'])\n",
    "        )\n",
    "\n",
    "result.sort(key=lambda tup:tup[0][1], reverse = True)\n",
    "\n",
    "for r in result:\n",
    "    print(\"| {} | {} | {} | {} |\".format(r[0][1], r[0][0], r[1].replace(\"|\",\" \"), r[2].replace(\"|\", \" \")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
